{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c8c7ff",
   "metadata": {},
   "source": [
    "# Model 12: RNN (Recurrent Neural Network) â€“ Step-by-Step\n",
    "Train a **vanilla RNN** on a real dataset: **IMDB movie review sentiment** (positive/negative).\n",
    "\n",
    "You will learn:\n",
    "1) What an RNN is (sequence + memory)\n",
    "2) How to prepare text as padded sequences\n",
    "3) How to build a `SimpleRNN` model\n",
    "4) How to train and evaluate\n",
    "5) Why vanilla RNNs struggle with long-range memory (motivation for LSTM/GRU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If TensorFlow is missing, uncomment:\n",
    "# !pip -q install tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b55f7",
   "metadata": {},
   "source": [
    "## 1) Load the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=num_words)\n",
    "\n",
    "print('Train samples:', len(x_train))\n",
    "print('Test samples :', len(x_test))\n",
    "print('Example review length (tokens):', len(x_train[0]))\n",
    "print('Label (0=neg, 1=pos):', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a6ed5",
   "metadata": {},
   "source": [
    "## 2) Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13419702",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test  = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print('Train shape:', x_train.shape)\n",
    "print('Test shape :', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b168cd1",
   "metadata": {},
   "source": [
    "## 3) Build a vanilla RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a119bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=num_words, output_dim=64, input_length=maxlen),\n",
    "    layers.SimpleRNN(64),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873726f7",
   "metadata": {},
   "source": [
    "## 4) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ce1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4833e",
   "metadata": {},
   "source": [
    "## 5) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faede43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87877349",
   "metadata": {},
   "source": [
    "## 6) Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('RNN Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('RNN Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b4726",
   "metadata": {},
   "source": [
    "## 7) Try your own text (simple helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba325a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "def encode_review(text: str, maxlen=200):\n",
    "    encoded = []\n",
    "    for w in text.lower().split():\n",
    "        idx = word_index.get(w)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        encoded.append(idx + 3)  # IMDB shifts indices by 3\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences([encoded], maxlen=maxlen)\n",
    "\n",
    "def predict_sentiment(text: str):\n",
    "    x = encode_review(text, maxlen=maxlen)\n",
    "    prob = float(model.predict(x, verbose=0)[0][0])\n",
    "    label = 'positive' if prob >= 0.5 else 'negative'\n",
    "    return label, prob\n",
    "\n",
    "examples = [\n",
    "    'this movie was fantastic with great acting and a wonderful story',\n",
    "    'boring film terrible plot and i fell asleep',\n",
    "]\n",
    "\n",
    "for t in examples:\n",
    "    label, prob = predict_sentiment(t)\n",
    "    print('Text:', t)\n",
    "    print('Prediction:', label, '| probability:', prob)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de7196",
   "metadata": {},
   "source": [
    "## 8) Why vanilla RNNs often struggle\n",
    "- **Vanishing/exploding gradients**\n",
    "- Weak long-term memory on long sequences\n",
    "- LSTM/GRU fix this with gates (next model)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}