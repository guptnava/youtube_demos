{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU in Python (Colab)\n",
    "\n",
    "This notebook teaches GRU (Gated Recurrent Unit) **step-by-step**:\n",
    "\n",
    "1. Intuition + equations\n",
    "2. Implement a **GRU cell from scratch** in PyTorch\n",
    "3. Train a small GRU model on a toy sequence task\n",
    "4. Tips: padding, packing, gradient clipping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "Colab usually includes PyTorch. If not, uncomment the install cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# !pip -q install torch\n",
    "\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GRU equations (reference)\n",
    "\n",
    "Given input $x_t$ and previous hidden state $h_{t-1}$:\n",
    "\n",
    "$$z_t=\\sigma(W_z x_t + U_z h_{t-1} + b_z)$$\n",
    "$$r_t=\\sigma(W_r x_t + U_r h_{t-1} + b_r)$$\n",
    "$$\\tilde{h}_t=\\tanh(W_h x_t + U_h (r_t \\odot h_{t-1}) + b_h)$$\n",
    "$$h_t=(1-z_t)\\odot h_{t-1} + z_t\\odot \\tilde{h}_t$$\n",
    "\n",
    "Where $\\odot$ is elementwise multiply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Implement a GRU cell from scratch (PyTorch)\n",
    "\n",
    "We\u2019ll build a module that consumes a **single time step**: `(x_t, h_prev) -> h_t`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCellScratch(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # We implement separate linear layers for clarity.\n",
    "        self.x2z = nn.Linear(input_size, hidden_size)\n",
    "        self.h2z = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "        self.x2r = nn.Linear(input_size, hidden_size)\n",
    "        self.h2r = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
    "        # x_t: (batch, input_size)\n",
    "        # h_prev: (batch, hidden_size)\n",
    "        z_t = torch.sigmoid(self.x2z(x_t) + self.h2z(h_prev))\n",
    "        r_t = torch.sigmoid(self.x2r(x_t) + self.h2r(h_prev))\n",
    "        h_tilde = torch.tanh(self.x2h(x_t) + self.h2h(r_t * h_prev))\n",
    "        h_t = (1 - z_t) * h_prev + z_t * h_tilde\n",
    "        return h_t\n",
    "\n",
    "# Quick shape test\n",
    "batch, input_size, hidden_size = 4, 6, 10\n",
    "cell = GRUCellScratch(input_size, hidden_size).to(device)\n",
    "x_t = torch.randn(batch, input_size, device=device)\n",
    "h_prev = torch.randn(batch, hidden_size, device=device)\n",
    "h_t = cell(x_t, h_prev)\n",
    "h_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Build a simple GRU sequence model (from scratch cell)\n",
    "\n",
    "We\u2019ll unroll the cell across time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUSequenceModelScratch(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.cell = GRUCellScratch(input_size, hidden_size)\n",
    "        self.readout = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, h0: torch.Tensor | None = None):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        b, t, _ = x.shape\n",
    "        if h0 is None:\n",
    "            h = torch.zeros(b, self.cell.hidden_size, device=x.device)\n",
    "        else:\n",
    "            h = h0\n",
    "        hs = []\n",
    "        for i in range(t):\n",
    "            h = self.cell(x[:, i, :], h)\n",
    "            hs.append(h)\n",
    "        H = torch.stack(hs, dim=1)  # (batch, seq_len, hidden)\n",
    "        y = self.readout(H[:, -1, :])  # final-step prediction\n",
    "        return y, H\n",
    "\n",
    "model = GRUSequenceModelScratch(input_size=6, hidden_size=24, output_size=1).to(device)\n",
    "x = torch.randn(8, 5, 6, device=device)\n",
    "y, H = model(x)\n",
    "y.shape, H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Toy task: \"Did we see a special symbol?\" (sequence classification)\n",
    "\n",
    "We create sequences of length `T` with one-hot vectors of size `V`.\n",
    "Label is **1** if token `special_id` appears anywhere, else **0**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(n=2000, T=20, V=12, special_id=3, p_special=0.3):\n",
    "    X = torch.zeros(n, T, V)\n",
    "    y = torch.zeros(n, 1)\n",
    "    for i in range(n):\n",
    "        has_special = (random.random() < p_special)\n",
    "        pos = random.randrange(T) if has_special else None\n",
    "        for t in range(T):\n",
    "            token = special_id if (pos is not None and t == pos) else random.randrange(V)\n",
    "            X[i, t, token] = 1.0\n",
    "        y[i, 0] = 1.0 if has_special else 0.0\n",
    "    return X, y\n",
    "\n",
    "T, V = 25, 16\n",
    "X, y = make_dataset(n=4000, T=T, V=V, special_id=7, p_special=0.5)\n",
    "\n",
    "# Train/val split\n",
    "idx = torch.randperm(X.size(0))\n",
    "train_idx, val_idx = idx[:3200], idx[3200:]\n",
    "X_train, y_train = X[train_idx].to(device), y[train_idx].to(device)\n",
    "X_val, y_val = X[val_idx].to(device), y[val_idx].to(device)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Train the scratch GRU model\n",
    "\n",
    "We\u2019ll use BCEWithLogitsLoss for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUSequenceModelScratch(input_size=V, hidden_size=64, output_size=1).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def accuracy(logits, y_true):\n",
    "    preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "    return (preds == y_true).float().mean().item()\n",
    "\n",
    "batch_size = 128\n",
    "for epoch in range(1, 11):\n",
    "    model.train()\n",
    "    perm = torch.randperm(X_train.size(0), device=device)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    steps = 0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        idxb = perm[i:i+batch_size]\n",
    "        xb, yb = X_train[idxb], y_train[idxb]\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits, _ = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        # Gradient clipping is common for RNNs\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuracy(logits.detach(), yb)\n",
    "        steps += 1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits, _ = model(X_val)\n",
    "        val_loss = loss_fn(val_logits, y_val).item()\n",
    "        val_acc = accuracy(val_logits, y_val)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train loss {total_loss/steps:.4f} acc {total_acc/steps:.3f} | val loss {val_loss:.4f} acc {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) The PyTorch built-in GRU\n",
    "\n",
    "`nn.GRU` handles batching efficiently and supports multi-layer + bidirectional GRUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUSequenceModelTorch(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.head = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out: (batch, seq_len, hidden)\n",
    "        out, h_n = self.gru(x)\n",
    "        logits = self.head(out[:, -1, :])\n",
    "        return logits\n",
    "\n",
    "model2 = GRUSequenceModelTorch(input_size=V, hidden_size=64).to(device)\n",
    "opt2 = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    model2.train()\n",
    "    perm = torch.randperm(X_train.size(0), device=device)\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        idxb = perm[i:i+batch_size]\n",
    "        xb, yb = X_train[idxb], y_train[idxb]\n",
    "        opt2.zero_grad(set_to_none=True)\n",
    "        logits = model2(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model2.parameters(), 1.0)\n",
    "        opt2.step()\n",
    "\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model2(X_val)\n",
    "        val_loss = loss_fn(val_logits, y_val).item()\n",
    "        val_acc = accuracy(val_logits, y_val)\n",
    "    print(f\"Epoch {epoch:02d} | val loss {val_loss:.4f} acc {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Next steps\n",
    "\n",
    "- Variable-length sequences: `pack_padded_sequence` / `pad_packed_sequence`\n",
    "- Time series forecasting: predict next value(s) instead of classification\n",
    "- Add dropout / layer norm / better token embeddings\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GRU_in_Python_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}