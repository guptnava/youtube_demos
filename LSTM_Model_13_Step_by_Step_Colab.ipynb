{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96817de0",
   "metadata": {},
   "source": [
    "# Model 13: LSTM (Long Short-Term Memory) â€“ Step-by-Step\n",
    "Train an **LSTM** for **text sentiment analysis** using the IMDB dataset.\n",
    "\n",
    "You will learn:\n",
    "1) Why LSTM is better than vanilla RNN\n",
    "2) How to prepare sequence data\n",
    "3) How to build an LSTM model\n",
    "4) Train, evaluate, and test on new text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efe4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If TensorFlow is missing, uncomment the next line:\n",
    "# !pip -q install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d102dc9",
   "metadata": {},
   "source": [
    "## 1) Load IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78221148",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=num_words)\n",
    "\n",
    "print('Train samples:', len(x_train))\n",
    "print('Test samples:', len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ead18",
   "metadata": {},
   "source": [
    "## 2) Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d491d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test  = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print('Train shape:', x_train.shape)\n",
    "print('Test shape :', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21df42",
   "metadata": {},
   "source": [
    "## 3) Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=num_words, output_dim=64, input_length=maxlen),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2feb1",
   "metadata": {},
   "source": [
    "## 4) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdf81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7f686",
   "metadata": {},
   "source": [
    "## 5) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e621b3df",
   "metadata": {},
   "source": [
    "## 6) Try your own text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e594f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "def encode_review(text, maxlen=200):\n",
    "    encoded = []\n",
    "    for w in text.lower().split():\n",
    "        idx = word_index.get(w)\n",
    "        if idx:\n",
    "            encoded.append(idx + 3)\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences([encoded], maxlen=maxlen)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    x = encode_review(text)\n",
    "    prob = float(model.predict(x, verbose=0)[0][0])\n",
    "    label = 'positive' if prob >= 0.5 else 'negative'\n",
    "    return label, prob\n",
    "\n",
    "examples = [\n",
    "    'this movie was amazing and inspiring',\n",
    "    'terrible movie boring and slow'\n",
    "]\n",
    "\n",
    "for t in examples:\n",
    "    label, prob = predict_sentiment(t)\n",
    "    print(t)\n",
    "    print('Prediction:', label, '| Probability:', prob)\n",
    "    print('-'*60)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}