{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414c4ce5",
   "metadata": {},
   "source": [
    "# Model 14: Transformers â€“ Step-by-Step (Text Classification)\n",
    "This notebook builds a **tiny Transformer encoder** for binary text classification.\n",
    "\n",
    "You will learn:\n",
    "- Tokenization with TextVectorization\n",
    "- Self-Attention (MultiHeadAttention)\n",
    "- Transformer encoder block\n",
    "- Train and evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If TensorFlow is missing, uncomment:\n",
    "# !pip -q install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b1a7b",
   "metadata": {},
   "source": [
    "## 1) Small example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'i love this movie',\n",
    "    'this film is amazing',\n",
    "    'terrible movie i hate it',\n",
    "    'worst film ever'\n",
    "]\n",
    "labels = [1, 1, 0, 0]\n",
    "y = tf.constant(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c048e",
   "metadata": {},
   "source": [
    "## 2) Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = layers.TextVectorization(max_tokens=2000, output_sequence_length=20)\n",
    "vectorizer.adapt(texts)\n",
    "X = vectorizer(texts)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387306d",
   "metadata": {},
   "source": [
    "## 3) Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e69742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation='relu'),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584576d9",
   "metadata": {},
   "source": [
    "## 4) Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "num_heads = 2\n",
    "ff_dim = 64\n",
    "maxlen = 20\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "x = layers.Embedding(input_dim=2000, output_dim=embed_dim)(inputs)\n",
    "x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af604c0c",
   "metadata": {},
   "source": [
    "## 5) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbae06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=30, verbose=0)\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6daa0a",
   "metadata": {},
   "source": [
    "## 6) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = ['i really enjoyed this film', 'this was awful']\n",
    "X_test = vectorizer(test_texts)\n",
    "preds = model.predict(X_test)\n",
    "for t, p in zip(test_texts, preds):\n",
    "    print(t, '->', float(p))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}