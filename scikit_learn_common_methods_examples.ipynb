{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c230a9d3",
   "metadata": {},
   "source": [
    "# Scikit-learn (sklearn) — Commonly Used Methods & Classes: Code Examples\n",
    "\n",
    "This Colab-ready notebook demonstrates the most commonly used scikit-learn methods/classes mentioned earlier: `fit`, `predict`, `predict_proba`, `score`, popular estimators, preprocessing, model selection, metrics, pipelines, and feature selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba269752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running in Google Colab, scikit-learn is usually preinstalled.\n",
    "# Uncomment to upgrade if needed:\n",
    "# !pip -q install -U scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Unsupervised + DR\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE, VarianceThreshold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Imports OK ✅\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af349c",
   "metadata": {},
   "source": [
    "## 1) Core estimator API: `fit`, `predict`, `predict_proba`, `score`\n",
    "Most sklearn estimators share this interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d13fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use Iris for classification\n",
    "iris = datasets.load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)            # fit\n",
    "y_pred = clf.predict(X_test)         # predict\n",
    "y_proba = clf.predict_proba(X_test)  # predict_proba (classification)\n",
    "acc = clf.score(X_test, y_test)      # score (default metric depends on estimator)\n",
    "\n",
    "acc, y_pred[:5], y_proba[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef830b2",
   "metadata": {},
   "source": [
    "## 2) Popular classification models\n",
    "Quick examples for: `LogisticRegression`, `RandomForestClassifier`, `DecisionTreeClassifier`, `SVC`, `KNeighborsClassifier`, `GaussianNB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_cls = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=300),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVC(probability=True)\": SVC(probability=True, random_state=42),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"GaussianNB\": GaussianNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, m in models_cls.items():\n",
    "    m.fit(X_train, y_train)\n",
    "    results[name] = m.score(X_test, y_test)\n",
    "\n",
    "pd.Series(results).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc08e2",
   "metadata": {},
   "source": [
    "## 3) Popular regression models\n",
    "Examples for: `LinearRegression`, `Ridge`, `Lasso`, `ElasticNet`, `RandomForestRegressor`, `DecisionTreeRegressor`, `SVR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed437ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# California Housing for regression\n",
    "cal = datasets.fetch_california_housing(as_frame=True)\n",
    "Xr = cal.data\n",
    "yr = cal.target\n",
    "\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.25, random_state=42)\n",
    "\n",
    "models_reg = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.001),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.001, l1_ratio=0.5),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=42, n_estimators=200, n_jobs=-1),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"SVR\": SVR(C=10.0, epsilon=0.1)\n",
    "}\n",
    "\n",
    "reg_metrics = {}\n",
    "for name, m in models_reg.items():\n",
    "    m.fit(Xr_train, yr_train)\n",
    "    pred = m.predict(Xr_test)\n",
    "    reg_metrics[name] = {\n",
    "        \"RMSE\": mean_squared_error(yr_test, pred, squared=False),\n",
    "        \"MAE\": mean_absolute_error(yr_test, pred),\n",
    "        \"R2\": r2_score(yr_test, pred),\n",
    "        \"score()\": m.score(Xr_test, yr_test)\n",
    "    }\n",
    "\n",
    "pd.DataFrame(reg_metrics).T.sort_values(\"R2\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405bd20",
   "metadata": {},
   "source": [
    "## 4) Data preprocessing\n",
    "### 4.1 Scaling & normalization: `StandardScaler`, `MinMaxScaler`, `RobustScaler`, `Normalizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X_small = X_train.iloc[:10].copy()\n",
    "\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),\n",
    "    \"MinMaxScaler\": MinMaxScaler(),\n",
    "    \"RobustScaler\": RobustScaler(),\n",
    "    \"Normalizer\": Normalizer()\n",
    "}\n",
    "\n",
    "scaled_samples = {}\n",
    "for name, s in scalers.items():\n",
    "    scaled_samples[name] = pd.DataFrame(s.fit_transform(X_small), columns=X_small.columns).head(3)\n",
    "\n",
    "scaled_samples[\"StandardScaler\"], scaled_samples[\"MinMaxScaler\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae6dc4",
   "metadata": {},
   "source": [
    "### 4.2 Encoding categorical data: `OneHotEncoder`, `LabelEncoder`, `OrdinalEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db136a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.DataFrame({\n",
    "    \"color\": [\"red\", \"blue\", \"green\", \"blue\"],\n",
    "    \"size\":  [\"S\", \"M\", \"L\", \"S\"]\n",
    "})\n",
    "\n",
    "# OneHotEncoder (for models; returns array / sparse matrix)\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "ohe_out = ohe.fit_transform(df_cat[[\"color\"]])\n",
    "\n",
    "# OrdinalEncoder (keeps order you define, or alphabetical by default)\n",
    "ord_enc = OrdinalEncoder(categories=[[\"S\", \"M\", \"L\"]])  # explicit order\n",
    "ord_out = ord_enc.fit_transform(df_cat[[\"size\"]])\n",
    "\n",
    "# LabelEncoder (typically for y labels, not X features)\n",
    "le = LabelEncoder()\n",
    "y_labels = le.fit_transform([\"spam\", \"ham\", \"spam\", \"eggs\"])\n",
    "\n",
    "ohe_out, ord_out.ravel(), y_labels, le.classes_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecd9f6",
   "metadata": {},
   "source": [
    "### 4.3 Missing values: `SimpleImputer`, `KNNImputer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss = pd.DataFrame({\n",
    "    \"a\": [1.0, np.nan, 3.0, 4.0],\n",
    "    \"b\": [np.nan, 2.0, 3.0, np.nan]\n",
    "})\n",
    "\n",
    "simp = SimpleImputer(strategy=\"mean\")\n",
    "knn = KNNImputer(n_neighbors=2)\n",
    "\n",
    "simp_out = pd.DataFrame(simp.fit_transform(df_miss), columns=df_miss.columns)\n",
    "knn_out  = pd.DataFrame(knn.fit_transform(df_miss), columns=df_miss.columns)\n",
    "\n",
    "df_miss, simp_out, knn_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e871464",
   "metadata": {},
   "source": [
    "## 5) Model selection & evaluation\n",
    "### 5.1 `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80acd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already used above, but here's the pattern:\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_train2.shape, X_test2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4beb0ea",
   "metadata": {},
   "source": [
    "### 5.2 Cross-validation: `cross_val_score`, `cross_validate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4903cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=300))\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring=\"accuracy\")\n",
    "cv = cross_validate(pipe, X, y, cv=5, scoring=[\"accuracy\", \"f1_macro\"], return_train_score=True)\n",
    "\n",
    "scores, {k: np.mean(v) for k, v in cv.items() if k.startswith(\"test_\")}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336453b",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter search: `GridSearchCV`, `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179875be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV example for SVC\n",
    "svc_pipe = make_pipeline(StandardScaler(), SVC(probability=True, random_state=42))\n",
    "param_grid = {\n",
    "    \"svc__C\": [0.1, 1, 10],\n",
    "    \"svc__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "grid = GridSearchCV(svc_pipe, param_grid=param_grid, cv=3, scoring=\"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.best_params_, grid.best_score_, grid.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV example for RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_dist = {\n",
    "    \"n_estimators\": randint(50, 400),\n",
    "    \"max_depth\": randint(2, 20),\n",
    "    \"min_samples_split\": randint(2, 10)\n",
    "}\n",
    "rand = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=12, cv=3, scoring=\"accuracy\", random_state=42, n_jobs=-1)\n",
    "rand.fit(X_train, y_train)\n",
    "\n",
    "rand.best_params_, rand.best_score_, rand.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee3385",
   "metadata": {},
   "source": [
    "### 5.4 Metrics (classification)\n",
    "`accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_auc_score`, `confusion_matrix`, `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca497b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use breast cancer dataset (binary classification)\n",
    "bc = datasets.load_breast_cancer(as_frame=True)\n",
    "Xb = bc.data\n",
    "yb = bc.target\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(Xb, yb, test_size=0.25, random_state=42, stratify=yb)\n",
    "\n",
    "clf_b = make_pipeline(StandardScaler(), LogisticRegression(max_iter=500))\n",
    "clf_b.fit(Xb_train, yb_train)\n",
    "\n",
    "pred_b = clf_b.predict(Xb_test)\n",
    "proba_b = clf_b.predict_proba(Xb_test)[:, 1]\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(yb_test, pred_b),\n",
    "    \"precision\": precision_score(yb_test, pred_b),\n",
    "    \"recall\": recall_score(yb_test, pred_b),\n",
    "    \"f1\": f1_score(yb_test, pred_b),\n",
    "    \"roc_auc\": roc_auc_score(yb_test, proba_b),\n",
    "}\n",
    "metrics, confusion_matrix(yb_test, pred_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20086c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(yb_test, pred_b, target_names=bc.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7b060",
   "metadata": {},
   "source": [
    "### 5.5 Metrics (regression)\n",
    "`mean_squared_error`, `mean_absolute_error`, `r2_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n",
    "reg.fit(Xr_train, yr_train)\n",
    "pred_r = reg.predict(Xr_test)\n",
    "\n",
    "rmse = mean_squared_error(yr_test, pred_r, squared=False)\n",
    "mae = mean_absolute_error(yr_test, pred_r)\n",
    "r2  = r2_score(yr_test, pred_r)\n",
    "\n",
    "{\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"score()\": reg.score(Xr_test, yr_test)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b34a4",
   "metadata": {},
   "source": [
    "## 6) Pipelines & composition\n",
    "### `Pipeline`, `make_pipeline`, `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddefb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toy mixed-type dataset\n",
    "df = pd.DataFrame({\n",
    "    \"age\": [25, 32, 47, np.nan, 52, 23],\n",
    "    \"income\": [50000, 64000, 120000, 58000, np.nan, 48000],\n",
    "    \"city\": [\"London\", \"Paris\", \"London\", \"Berlin\", \"Paris\", \"Berlin\"],\n",
    "    \"segment\": [\"A\", \"B\", \"A\", \"C\", \"B\", \"A\"]\n",
    "})\n",
    "y_toy = np.array([0, 1, 0, 1, 1, 0])\n",
    "\n",
    "num_cols = [\"age\", \"income\"]\n",
    "cat_cols = [\"city\", \"segment\"]\n",
    "\n",
    "numeric_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_tf, num_cols),\n",
    "        (\"cat\", categorical_tf, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=300))\n",
    "])\n",
    "\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(df, y_toy, test_size=0.33, random_state=42, stratify=y_toy)\n",
    "full_model.fit(X_train_t, y_train_t)\n",
    "full_model.score(X_test_t, y_test_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdeb720",
   "metadata": {},
   "source": [
    "## 7) Feature selection\n",
    "`SelectKBest`, `chi2`, `f_classif`, `RFE`, `VarianceThreshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b43523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For chi2, features must be non-negative\n",
    "X_nonneg = MinMaxScaler().fit_transform(X)  # iris scaled to [0,1]\n",
    "\n",
    "# SelectKBest + chi2\n",
    "skb_chi2 = SelectKBest(score_func=chi2, k=2)\n",
    "X_chi2 = skb_chi2.fit_transform(X_nonneg, y)\n",
    "chi2_selected = np.array(iris.feature_names)[skb_chi2.get_support()]\n",
    "\n",
    "# SelectKBest + f_classif (ANOVA)\n",
    "skb_f = SelectKBest(score_func=f_classif, k=2)\n",
    "X_f = skb_f.fit_transform(X, y)\n",
    "f_selected = np.array(iris.feature_names)[skb_f.get_support()]\n",
    "\n",
    "chi2_selected, f_selected, X_chi2.shape, X_f.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with LogisticRegression\n",
    "rfe = RFE(estimator=LogisticRegression(max_iter=300), n_features_to_select=2)\n",
    "rfe.fit(X, y)\n",
    "rfe_selected = np.array(iris.feature_names)[rfe.get_support()]\n",
    "\n",
    "# VarianceThreshold\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "vt.fit(X)\n",
    "vt_selected = np.array(iris.feature_names)[vt.get_support()]\n",
    "\n",
    "rfe_selected, vt_selected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587256a",
   "metadata": {},
   "source": [
    "## 8) Clustering\n",
    "`KMeans`, `DBSCAN`, `AgglomerativeClustering`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u = StandardScaler().fit_transform(iris.data)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=\"auto\")\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=5)\n",
    "agglo = AgglomerativeClustering(n_clusters=3)\n",
    "\n",
    "labels_k = kmeans.fit_predict(X_u)\n",
    "labels_d = dbscan.fit_predict(X_u)\n",
    "labels_a = agglo.fit_predict(X_u)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"KMeans\": labels_k,\n",
    "    \"DBSCAN\": labels_d,\n",
    "    \"Agglomerative\": labels_a\n",
    "}).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e366e31",
   "metadata": {},
   "source": [
    "## 9) Dimensionality reduction / visualization\n",
    "`PCA`, `TruncatedSVD`, `TSNE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(iris.data)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "X_svd = svd.fit_transform(X_std)\n",
    "\n",
    "# t-SNE can be slow on large datasets; Iris is small.\n",
    "tsne = TSNE(n_components=2, random_state=42, init=\"pca\", learning_rate=\"auto\")\n",
    "X_tsne = tsne.fit_transform(X_std)\n",
    "\n",
    "X_pca[:3], X_svd[:3], X_tsne[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337be142",
   "metadata": {},
   "source": [
    "## ✅ Done\n",
    "You now have runnable examples for the commonly used scikit-learn methods/classes listed earlier."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
