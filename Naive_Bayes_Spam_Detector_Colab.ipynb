{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3102fb8d",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Real-World Spam Detection with Naive Bayes (SMS Spam)\n",
    "Build a **spam detector** using the classic **SMS Spam Collection** dataset (ham vs spam).\n",
    "\n",
    "You will:\n",
    "1) Download dataset\n",
    "2) Load & clean text\n",
    "3) Text â†’ numbers (TFâ€‘IDF)\n",
    "4) Train **Multinomial Naive Bayes**\n",
    "5) Evaluate (accuracy + precision/recall/F1 + confusion matrix)\n",
    "6) Inspect top spam/ham words\n",
    "7) Try your own messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef444042",
   "metadata": {},
   "source": [
    "## 1) Download & load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a083831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, zipfile, requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip'\n",
    "r = requests.get(url, timeout=60)\n",
    "r.raise_for_status()\n",
    "\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "print('Files in zip:', z.namelist())\n",
    "\n",
    "with z.open('SMSSpamCollection') as f:\n",
    "    raw = f.read().decode('utf-8', errors='replace')\n",
    "\n",
    "rows = [line.split('\\t', 1) for line in raw.splitlines() if '\\t' in line]\n",
    "df = pd.DataFrame(rows, columns=['label', 'text'])\n",
    "df['label'] = df['label'].str.strip()\n",
    "df['text'] = df['text'].str.strip()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset size:', len(df))\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e3c7f",
   "metadata": {},
   "source": [
    "## 2) Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print('Train:', len(X_train), 'Test:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a95b44",
   "metadata": {},
   "source": [
    "## 3) Text â†’ numbers (TFâ€‘IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ec3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print('Vectorized shape:', X_train_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8f881",
   "metadata": {},
   "source": [
    "## 4) Train Naive Bayes (MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ad2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB(alpha=0.5)  # smoothing\n",
    "nb.fit(X_train_vec, y_train)\n",
    "print('Model trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af766534",
   "metadata": {},
   "source": [
    "## 5) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b29bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = nb.predict(X_test_vec)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('\\nConfusion Matrix (rows=true, cols=pred):')\n",
    "print(confusion_matrix(y_test, y_pred, labels=['ham','spam']))\n",
    "\n",
    "print('\\nReport:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bde06c",
   "metadata": {},
   "source": [
    "## 6) Inspect top spam/ham words (what the model learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "class_index = {c:i for i,c in enumerate(nb.classes_)}\n",
    "spam_i = class_index['spam']\n",
    "ham_i  = class_index['ham']\n",
    "\n",
    "# Higher = more spammy\n",
    "scores = nb.feature_log_prob_[spam_i] - nb.feature_log_prob_[ham_i]\n",
    "\n",
    "top_spam = feature_names[np.argsort(scores)[-20:]][::-1]\n",
    "top_ham  = feature_names[np.argsort(scores)[:20]]\n",
    "\n",
    "print('Top indicators of SPAM:')\n",
    "print(', '.join(top_spam))\n",
    "print('\\nTop indicators of HAM:')\n",
    "print(', '.join(top_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dbea92",
   "metadata": {},
   "source": [
    "## 7) Try your own messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0205ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_message(msg: str):\n",
    "    vec = vectorizer.transform([msg])\n",
    "    pred = nb.predict(vec)[0]\n",
    "    proba = nb.predict_proba(vec)[0]\n",
    "    return pred, {cls: float(p) for cls, p in zip(nb.classes_, proba)}\n",
    "\n",
    "examples = [\n",
    "    'WIN a free vacation now!!! Click here to claim',\n",
    "    'Hey are we still on for dinner at 7?',\n",
    "    'URGENT! You have won a 1000 cash prize. Call now',\n",
    "]\n",
    "\n",
    "for m in examples:\n",
    "    pred, proba = predict_message(m)\n",
    "    print('Message:', m)\n",
    "    print('Prediction:', pred)\n",
    "    print('Probabilities:', proba)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8158f",
   "metadata": {},
   "source": [
    "## 8) Next upgrades (optional)\n",
    "- Compare TFâ€‘IDF vs CountVectorizer\n",
    "- Tune `alpha`\n",
    "- Try Logistic Regression / Linear SVM\n",
    "- Add text cleaning (URLs, phone numbers, etc.)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}